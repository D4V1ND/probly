<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" />

    <!-- Generated with Sphinx 8.2.3 and Furo 2024.08.06 -->
        <title>An Introduction To Model Calibration With Probly - probly 0.3.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=354aac6f" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=302659d7" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=201d0c9a" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">probly 0.3.1 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><div class="sidebar-scroll"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../_static/logo/logo_light.png" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../_static/logo/logo_dark.png" alt="Dark Logo"/>
  </div>
  
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Content</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">The <code class="docutils literal notranslate"><span class="pre">probly</span></code> Python Package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../core_concepts.html">Core Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../main_components.html">Main Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced_topics.html">Advanced Topics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples_and_tutorials.html">Examples and Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../methods.html">Implemented methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to probly üèîÔ∏è</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">References and Further Reading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ and Troubleshooting</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Notebooks</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../notebooks/examples/index.html">Notebook Examples</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Notebook Examples</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/examples/utilities_and_layers/index.html">Utilities and Layers</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Utilities and Layers</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/examples/utilities_and_layers/custom_loss_functions.html">Custom Loss Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/examples/utilities_and_layers/metrics.html">Evaluation Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/examples/utilities_and_layers/probabilistic_layers.html">Key Probabilistic Layers in <code class="docutils literal notranslate"><span class="pre">probly</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/examples/utilities_and_layers/utility_functions.html">Utility Functions</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../notebooks/examples/evaluation_and_quantification/index.html">Evaluation and Quantification</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Evaluation and Quantification</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/examples/evaluation_and_quantification/calibration_metrics.html">Calibration Metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/examples/evaluation_and_quantification/interpretation_techniques.html">Interpretation techniques</a></li>
<li class="toctree-l3"><a class="reference internal" href="../notebooks/examples/evaluation_and_quantification/visualization_tools.html">Visualisation Tools</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/bayesian_transformation.html">Bayesian Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/dropconnect_transformation.html">Dropconnect Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/dropout_transformation.html">Dropout Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/ensemble_transformation.html">Ensemble Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/evidential_classification_transformation.html">Evidential Classification Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/evidential_regression_transformation.html">Evidential Regression Transformation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/fashionmnist_ood_ensemble.html">Out-of-Distribution Detection with an Ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/label_relaxation_calibration.html">Calibration with Label Relaxation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/lazy_dispatch_test.html">Lazy Dispatch Test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/multilib_demo.html">Multilib Demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/pytraverse_tutorial.html">A Brief Introduction to PyTraverse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/sklearn_selective_prediction.html">Using probly with scikit-learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/temperature_scaling_calibration.html">Calibration using Temperature Scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/train_bnn_classification.html">Bayesian Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/train_evidential_classification.html">Evidential Model for Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notebooks/examples/train_evidential_regression.html">Evidential Regression Model</a></li>
</ul>
</li>
</ul>

</div>
</div><div style="text-align: center; margin-top: 1rem; margin-bottom: 1rem;">
  <a href="https://github.com/pwhofman/probly" target="_blank" rel="noopener noreferrer" title="GitHub Repository">
    <img src="../_static/github-mark.svg" alt="GitHub Logo" width="28" height="28" style="display: inline-block;">
  </a>
</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          

<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="an-introduction-to-model-calibration-with-probly">
<h1>An Introduction To Model Calibration With Probly<a class="headerlink" href="#an-introduction-to-model-calibration-with-probly" title="Link to this heading">¬∂</a></h1>
<p>This notebook is a short introduction to post-processing calibration of neural networks with Probly.</p>
</section>
<section id="motivation-and-intuition">
<h1>0. Motivation and Intuition<a class="headerlink" href="#motivation-and-intuition" title="Link to this heading">¬∂</a></h1>
<p>A trained neural network might have good accuracy, but that is not all that we could wish for.<br />
Even if the accuracy of our model is good, it is possible that its confidence does not reflect the true likelyhood of the prediction being correct.</p>
<p><img alt="Model Confidence" src="https://creatis-myriad.github.io/collections/images/calibration/reliability_histogram.jpg" /></p>
<p>As you can see above models can be over or underconfident which means that they either overestimate or underestimate how accurate they are with their predictions.</p>
<p>But it would be nice to have a good estimate of the accuracy via the confidence, especially in very sensitive areas like medicine or AI assisted driving‚Ä¶</p>
</section>
<section id="what-is-calibration">
<h1>1. What is Calibration<a class="headerlink" href="#what-is-calibration" title="Link to this heading">¬∂</a></h1>
<p>This is where calibration - and in this case post-processing calibration - comes in.<br />
Calibration aims to push the confidence the model gives us to reflect the true accuracy for the inputs. So a perfectly calibrated model would give you a confidence and you would know that is also its accuracy.</p>
<p>There are two major ways to do calibration on neural networks:</p>
<ul class="simple">
<li><p>In-training calibration</p></li>
<li><p>Post-processing calibration</p></li>
</ul>
<p>In-training calibration methods would include certain loss functions like focal loss or a regularization method like dropout but we will focus on post-processing calibration since it can be applied to an already trained model withoud the need to modify or retrain it.</p>
</section>
<section id="calibration-with-probly">
<h1>2. Calibration with Probly<a class="headerlink" href="#calibration-with-probly" title="Link to this heading">¬∂</a></h1>
<p>Probly once again really simplifies the whole process by giving us the <code class="docutils literal notranslate"><span class="pre">Calibrator</span></code> classes for the various frameworks.<br />
But to look at some calibrations we need something to calibrate in the first place, so lets define a model for that we can use. We will be using torch here, but other frameworks work just the same.</p>
<section id="load-the-model">
<h2>2.1 Load the model<a class="headerlink" href="#load-the-model" title="Link to this heading">¬∂</a></h2>
<p>We are going to use the pretrained ResNet18 Model from Torchvision for simplicity.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span><span class="p">,</span> <span class="n">random_split</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">ResNet18_Weights</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">T</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;mps&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">mps</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">ResNet18_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
<span class="n">net</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">net_binary</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">ResNet18_Weights</span><span class="o">.</span><span class="n">IMAGENET1K_V1</span><span class="p">)</span>
<span class="n">net_binary</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="n">net_binary</span> <span class="o">=</span> <span class="n">net_binary</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using device: mps
</pre></div>
</div>
</div>
</div>
</section>
<section id="load-the-data">
<h2>2.2 Load the data<a class="headerlink" href="#load-the-data" title="Link to this heading">¬∂</a></h2>
<p>Firstly, two datasets are loaded:</p>
<ul class="simple">
<li><p>Multi-class classification dataset with 10 classes (CIFAR-10)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">transforms</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">T</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()])</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">&quot;~/datasets&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">)</span>
<span class="n">train</span><span class="p">,</span> <span class="n">cal</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">&quot;~/datasets&quot;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">cal_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">cal</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Binary classification dataset derived from CIFAR-10, using a single class as the positive class</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">binarize_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">positive_class</span><span class="p">):</span>
    <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">img</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
        <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">1.0</span> <span class="k">if</span> <span class="n">label</span> <span class="o">==</span> <span class="n">positive_class</span> <span class="k">else</span> <span class="mf">0.0</span><span class="p">)</span>
    <span class="n">images</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>  <span class="c1"># shape: [N, C, H, W]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span>

<span class="n">positive_class</span> <span class="o">=</span> <span class="mi">1</span> 
<span class="n">x_train_full</span><span class="p">,</span> <span class="n">y_train_full</span> <span class="o">=</span> <span class="n">binarize_dataset</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">positive_class</span><span class="p">)</span>
<span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">binarize_dataset</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">positive_class</span><span class="p">)</span>

<span class="c1"># Split train</span>
<span class="n">val_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.2</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_train_full</span><span class="p">))</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_train_full</span><span class="p">)</span> <span class="o">-</span> <span class="n">val_size</span>

<span class="n">train_dataset</span><span class="p">,</span> <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span>
    <span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_train_full</span><span class="p">,</span> <span class="n">y_train_full</span><span class="p">),</span>
    <span class="p">[</span><span class="n">train_size</span><span class="p">,</span> <span class="n">val_size</span><span class="p">],</span>
    <span class="n">generator</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="n">train_loader_binary</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_loader_binary</span>   <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">test_loader_binary</span>  <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">TensorDataset</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-the-model">
<h2>2.3 Train the model<a class="headerlink" href="#train-the-model" title="Link to this heading">¬∂</a></h2>
<p>So let‚Äôs give the model a quick training session with our datasets.</p>
<p><strong>Training the multi-class model:</strong><br />
In this cell, we train a neural network to classify samples into <strong>10 classes</strong>. We use <code class="docutils literal notranslate"><span class="pre">CrossEntropyLoss</span></code> with the Adam optimizer, and print the running loss to monitor learning progress.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)):</span>
    <span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">, Running loss: </span><span class="si">{</span><span class="n">running_loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 20%|‚ñà‚ñà        | 1/5 [00:14&lt;00:56, 14.16s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1, Running loss: 0.9162294838079221
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:30&lt;00:46, 15.44s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2, Running loss: 0.5603881596000331
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:50&lt;00:34, 17.49s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3, Running loss: 0.4138178149606012
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [01:06&lt;00:16, 16.98s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4, Running loss: 0.3153723790577263
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:30&lt;00:00, 18.01s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5, Running loss: 0.2441058292700227
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
<p><strong>Training the binary model:</strong><br />
Here, we train a neural network for <strong>binary classification</strong>. The model outputs logits and is trained with <code class="docutils literal notranslate"><span class="pre">BCEWithLogitsLoss</span></code> and the Adam optimizer. Targets are converted to floats for compatibility, and the running loss is displayed for tracking training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net_binary</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>

<span class="n">best_val_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)):</span>
    <span class="n">net_binary</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">train_loader_binary</span><span class="p">:</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">net_binary</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">, Running loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 20%|‚ñà‚ñà        | 1/5 [00:15&lt;01:03, 15.79s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1, Running loss: 0.4301463137054519
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:31&lt;00:46, 15.50s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 2, Running loss: 0.3062203222067113
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:46&lt;00:30, 15.43s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 3, Running loss: 0.24051434948898046
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [01:01&lt;00:15, 15.39s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 4, Running loss: 0.1797389664248249
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:17&lt;00:00, 15.45s/it]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 5, Running loss: 0.15499286798190823
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="a-quick-look-at-the-model">
<h2>2.4 A quick look at the model<a class="headerlink" href="#a-quick-look-at-the-model" title="Link to this heading">¬∂</a></h2>
<p>For evaluation purposes probly gives us the function <code class="docutils literal notranslate"><span class="pre">expected_calibration_error()</span></code> to give us an idea of how uncalibrated the model really is.<br />
Now that we have something to work with, lets take a quick look at the calibration error of the uncalibrated model‚Ä¶</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">probly.calibration.visualization.reliability_diagram</span><span class="w"> </span><span class="kn">import</span> <span class="n">compute_reliability_diagram</span><span class="p">,</span> <span class="n">plot_reliability_diagram</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">probly.evaluation.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">brier_score</span><span class="p">,</span> <span class="n">expected_calibration_error</span><span class="p">,</span> <span class="n">expected_calibration_error_binary</span>

<span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">inpt</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_loader</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">outputs</span><span class="p">,</span> <span class="n">net</span><span class="p">(</span><span class="n">inpt</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">targets</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">correct</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">total</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">outputs_np</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">targets_np</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">ece</span> <span class="o">=</span> <span class="n">expected_calibration_error</span><span class="p">(</span><span class="n">outputs_np</span><span class="p">,</span> <span class="n">targets_np</span><span class="p">,</span> <span class="n">num_bins</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy: </span><span class="si">{</span><span class="n">correct</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">total</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected Calibration Error: </span><span class="si">{</span><span class="n">ece</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">brier_calibrated</span> <span class="o">=</span> <span class="n">brier_score</span><span class="p">(</span><span class="n">outputs_np</span><span class="p">,</span> <span class="n">targets_np</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Brier Score: </span><span class="si">{</span><span class="n">brier_calibrated</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">diagram</span> <span class="o">=</span> <span class="n">compute_reliability_diagram</span><span class="p">(</span><span class="n">outputs_np</span><span class="p">,</span> <span class="n">targets_np</span><span class="p">)</span>
<span class="n">plot_reliability_diagram</span><span class="p">(</span><span class="n">diagram</span><span class="p">,</span> <span class="s2">&quot;Regular Model&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:01&lt;00:00, 25.95it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.7891
Expected Calibration Error: 0.09911170146763325
Brier Score: 0.3159113824367523
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&lt;Figure size 640x480 with 1 Axes&gt;,
 &lt;Axes: title={&#39;center&#39;: &#39;Regular Model&#39;}, xlabel=&#39;Confidence&#39;, ylabel=&#39;Accuracy&#39;&gt;)
</pre></div>
</div>
<img alt="../_images/7fca35799285fd7f84858cc1bd419860cb13e61f9b4a07b0c3d3824342881683.png" src="../_images/7fca35799285fd7f84858cc1bd419860cb13e61f9b4a07b0c3d3824342881683.png" />
</div>
</div>
</section>
</section>
<section id="histogram-binning">
<h1>3. Histogram Binning<a class="headerlink" href="#histogram-binning" title="Link to this heading">¬∂</a></h1>
<section id="what-is-histogram-binning">
<h2>3.1 What is Histogram Binning?<a class="headerlink" href="#what-is-histogram-binning" title="Link to this heading">¬∂</a></h2>
<p>Histogram Binning is a simple non-parametric calibration method, where all uncalibrated predictions are divided into mutually exclusive bins. Every bin gets a calibrated score assigned, so that if a prediction falls into bin A for example, the prediction would be ‚Äúcalibrated‚Äù to the calibrated score of bin A.</p>
</section>
<section id="histogram-binning-with-probly">
<h2>3.2 Histogram Binning with Probly<a class="headerlink" href="#histogram-binning-with-probly" title="Link to this heading">¬∂</a></h2>
<p>TODO: Implementation of Histogram Binning with Probly</p>
</section>
</section>
<section id="temperature-scaling">
<h1>4. Temperature Scaling<a class="headerlink" href="#temperature-scaling" title="Link to this heading">¬∂</a></h1>
<section id="what-is-temperature-scaling">
<h2>4.1 What is Temperature Scaling?<a class="headerlink" href="#what-is-temperature-scaling" title="Link to this heading">¬∂</a></h2>
<p>Temperature scaling is a simple way to make a model‚Äôs confidence more honest. Many machine learning models, especially neural networks, are good at predicting the right class but tend to be too confident about their answers. Temperature scaling fixes this by slightly adjusting the model‚Äôs output probabilities after training. It does this by dividing the model‚Äôs raw scores by a value called the temperature, which can make the probabilities softer and less extreme. A higher temperature makes the model more cautious, while a lower one makes it more confident. The best temperature is learned using a validation set. Importantly, this process doesn‚Äôt change what the model predicts‚Äîit only makes the confidence behind those predictions more realistic and easier to trust.</p>
</section>
<section id="temperature-scaling-with-probly">
<h2>4.2 Temperature Scaling with Probly<a class="headerlink" href="#temperature-scaling-with-probly" title="Link to this heading">¬∂</a></h2>
<p>This code applies temperature scaling to calibrate a neural network‚Äôs predicted probabilities by learning a temperature parameter on a separate calibration dataset while keeping the model weights fixed. After calibration, the model generates probability predictions on the test set, which are then evaluated using Expected Calibration Error (ECE) to measure the gap between confidence and accuracy, and the Brier Score to assess overall probabilistic accuracy. Finally, a reliability diagram is plotted to visually show how well the model‚Äôs predicted confidence aligns with actual performance, where predictions closer to the diagonal indicate better calibration.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">probly.calibration.plattvectortemperature.common</span><span class="w"> </span><span class="kn">import</span> <span class="n">temperature</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">probly.calibration.visualization.reliability_diagram</span><span class="w"> </span><span class="kn">import</span> <span class="n">compute_reliability_diagram</span><span class="p">,</span> <span class="n">plot_reliability_diagram</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">probly.evaluation.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">brier_score</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">temperature</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cal_loader</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="n">all_targets</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_probs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_probs_before</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">inpt</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inpt</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">all_probs_before</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">probs</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>

        <span class="n">all_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inpt</span><span class="p">))</span>
        <span class="n">all_targets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

<span class="n">all_probs_before</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_probs_before</span><span class="p">)</span>
<span class="n">all_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_probs</span><span class="p">)</span>
<span class="n">all_targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_targets</span><span class="p">)</span>
<span class="n">all_probs_before_np</span> <span class="o">=</span> <span class="n">all_probs_before</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">all_probs_np</span> <span class="o">=</span> <span class="n">all_probs</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">all_targets_np</span> <span class="o">=</span> <span class="n">all_targets</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">ece_calibrated</span> <span class="o">=</span> <span class="n">expected_calibration_error</span><span class="p">(</span><span class="n">all_probs_np</span><span class="p">,</span> <span class="n">all_targets_np</span><span class="p">,</span> <span class="n">num_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected Calibration Error, after Temperature Scaling: </span><span class="si">{</span><span class="n">ece_calibrated</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">brier_calibrated</span> <span class="o">=</span> <span class="n">brier_score</span><span class="p">(</span><span class="n">all_probs_np</span><span class="p">,</span> <span class="n">all_targets_np</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Brier Score, after Temperature Scaling: </span><span class="si">{</span><span class="n">brier_calibrated</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">diagram</span> <span class="o">=</span> <span class="n">compute_reliability_diagram</span><span class="p">(</span><span class="n">all_probs_np</span><span class="p">,</span> <span class="n">all_targets_np</span><span class="p">)</span>
<span class="n">plot_reliability_diagram</span><span class="p">(</span><span class="n">diagram</span><span class="p">,</span> <span class="s2">&quot;Temperature Scaling&quot;</span><span class="p">)</span>
<span class="n">diagram_before</span> <span class="o">=</span> <span class="n">compute_reliability_diagram</span><span class="p">(</span><span class="n">all_probs_before_np</span><span class="p">,</span> <span class="n">all_targets_np</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:01&lt;00:00, 28.02it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Expected Calibration Error, after Temperature Scaling: 0.06339480333924294
Brier Score, after Temperature Scaling: 0.30308997631073
</pre></div>
</div>
<img alt="../_images/24f0684e4e93b2919bcb20d138e4e8a61798dc9189f5f3f500acb90592cfd659.png" src="../_images/24f0684e4e93b2919bcb20d138e4e8a61798dc9189f5f3f500acb90592cfd659.png" />
</div>
</div>
</section>
</section>
<section id="platt-scaling">
<h1>5. Platt Scaling<a class="headerlink" href="#platt-scaling" title="Link to this heading">¬∂</a></h1>
<section id="what-is-platt-scaling">
<h2>5.1 What is Platt Scaling?<a class="headerlink" href="#what-is-platt-scaling" title="Link to this heading">¬∂</a></h2>
<p>Platt scaling is a probability calibration technique used in machine learning to transform a classifier‚Äôs raw output scores into well-calibrated probability estimates for binary classification problems. It fits a logistic (sigmoid) function to the model‚Äôs predictions using a separate validation dataset, learning parameters that align predicted probabilities with observed class frequencies. This approach is commonly applied to models such as Support Vector Machines, which produce decision scores that are effective for ranking but not directly interpretable as probabilities.</p>
</section>
<section id="plat-scaling-with-probly">
<h2>5.2 Plat Scaling with Probly<a class="headerlink" href="#plat-scaling-with-probly" title="Link to this heading">¬∂</a></h2>
<p>This code applies TorchAffine calibration to the binary model. The calibration is fitted on the validation set, and we collect predicted probabilities before and after calibration on the test set. Probabilities and true labels are stored as NumPy arrays for ECE evaluation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">probly.calibration.plattvectortemperature.common</span><span class="w"> </span><span class="kn">import</span> <span class="n">affine</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">affine</span><span class="p">(</span><span class="n">net_binary</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">val_loader_binary</span><span class="p">)</span>

<span class="n">all_targets</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_probs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_probs_before</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">net_binary</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">inpt</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader_binary</span><span class="p">:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">net_binary</span><span class="p">(</span><span class="n">inpt</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
        <span class="n">all_probs_before</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">probs</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>

        <span class="n">all_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inpt</span><span class="p">))</span>
        <span class="n">all_targets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

<span class="n">all_probs_before</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_probs_before</span><span class="p">)</span>
<span class="n">all_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_probs</span><span class="p">)</span>
<span class="n">all_targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_targets</span><span class="p">)</span>

<span class="n">all_probs_before_np</span> <span class="o">=</span> <span class="n">all_probs_before</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">all_probs_np</span> <span class="o">=</span> <span class="n">all_probs</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">all_targets_np</span> <span class="o">=</span> <span class="n">all_targets</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">ece_before</span> <span class="o">=</span> <span class="n">expected_calibration_error_binary</span><span class="p">(</span><span class="n">all_probs_before_np</span><span class="p">,</span> <span class="n">all_targets_np</span><span class="p">)</span>
<span class="n">ece_after</span> <span class="o">=</span> <span class="n">expected_calibration_error_binary</span><span class="p">(</span><span class="n">all_probs_np</span><span class="p">,</span> <span class="n">all_targets_np</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected Calibration Error before Platt Scaling calibration: </span><span class="si">{</span><span class="n">ece_before</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected Calibration Error after Platt Scaling calibration: </span><span class="si">{</span><span class="n">ece_after</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [00:01&lt;00:00, 108.10it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Expected Calibration Error before Platt Scaling calibration: 0.0100496136426926
Expected Calibration Error after Platt Scaling calibration: 0.007241689932346363
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="vector-scaling">
<h1>6. Vector Scaling<a class="headerlink" href="#vector-scaling" title="Link to this heading">¬∂</a></h1>
<section id="what-is-vector-scaling">
<h2>6.1 What is Vector Scaling?<a class="headerlink" href="#what-is-vector-scaling" title="Link to this heading">¬∂</a></h2>
<p>Vector Scaling is an extension of Platt scaling for multi-class problems. It applies a learned scale and bias to each class‚Äôs logits, improving calibration so the predicted probabilities better match the true class frequencies.</p>
</section>
<section id="vector-scaling-with-probly">
<h2>6.2 Vector Scaling with Probly<a class="headerlink" href="#vector-scaling-with-probly" title="Link to this heading">¬∂</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">probly.calibration.plattvectortemperature.common</span><span class="w"> </span><span class="kn">import</span> <span class="n">affine</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">affine</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cal_loader</span><span class="p">)</span>

<span class="n">all_targets</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_probs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">all_probs_before</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">inpt</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inpt</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
        <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
        <span class="n">all_probs_before</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">probs</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>

        <span class="n">all_probs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">inpt</span><span class="p">))</span>
        <span class="n">all_targets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

<span class="n">all_probs_before</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_probs_before</span><span class="p">)</span>
<span class="n">all_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_probs</span><span class="p">)</span>
<span class="n">all_targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_targets</span><span class="p">)</span>

<span class="n">all_probs_before_np</span> <span class="o">=</span> <span class="n">all_probs_before</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">all_probs_np</span> <span class="o">=</span> <span class="n">all_probs</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">all_targets_np</span> <span class="o">=</span> <span class="n">all_targets</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">ece_calibrated</span> <span class="o">=</span> <span class="n">expected_calibration_error</span><span class="p">(</span><span class="n">all_probs_np</span><span class="p">,</span> <span class="n">all_targets_np</span><span class="p">,</span> <span class="n">num_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected Calibration Error, after Temperature Scaling: </span><span class="si">{</span><span class="n">ece_calibrated</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">brier_calibrated</span> <span class="o">=</span> <span class="n">brier_score</span><span class="p">(</span><span class="n">all_probs_np</span><span class="p">,</span> <span class="n">all_targets_np</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Brier Score, after Temperature Scaling: </span><span class="si">{</span><span class="n">brier_calibrated</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">diagram_vector</span> <span class="o">=</span> <span class="n">compute_reliability_diagram</span><span class="p">(</span><span class="n">all_probs_np</span><span class="p">,</span> <span class="n">all_targets_np</span><span class="p">)</span>
<span class="n">plot_reliability_diagram</span><span class="p">(</span><span class="n">diagram_vector</span><span class="p">,</span> <span class="s2">&quot;Vector Scaling&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:01&lt;00:00, 28.37it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Expected Calibration Error, after Temperature Scaling: 0.05921627366244792
Brier Score, after Temperature Scaling: 0.2941683530807495
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&lt;Figure size 640x480 with 1 Axes&gt;,
 &lt;Axes: title={&#39;center&#39;: &#39;Vector Scaling&#39;}, xlabel=&#39;Confidence&#39;, ylabel=&#39;Accuracy&#39;&gt;)
</pre></div>
</div>
<img alt="../_images/2dee7e70d1bfddd15c5d6143f1e3239949f6b475804319bf753de2fe2716d0d0.png" src="../_images/2dee7e70d1bfddd15c5d6143f1e3239949f6b475804319bf753de2fe2716d0d0.png" />
</div>
</div>
</section>
</section>
<section id="isotonic-regression">
<h1>7. Isotonic Regression<a class="headerlink" href="#isotonic-regression" title="Link to this heading">¬∂</a></h1>
<section id="what-is-isotonic-regression">
<h2>7.1 What is Isotonic Regression?<a class="headerlink" href="#what-is-isotonic-regression" title="Link to this heading">¬∂</a></h2>
<p>Isotonic Regression is one of the most common non-parametric post-processing calibration methods. It learns a piecewise constant function to transform uncalibrated model outputs and aims to minimize the square loss.<br />
It can be seen as a strict generalization of histogram binning.</p>
</section>
<section id="isotonic-regression-with-probly">
<h2>7.2 Isotonic Regression with Probly<a class="headerlink" href="#isotonic-regression-with-probly" title="Link to this heading">¬∂</a></h2>
<p>Let‚Äôs calibrate our base model with probly‚Äôs isotonic regression and again, compare it to the base model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">probly.calibration.isotonic_regression.common</span><span class="w"> </span><span class="kn">import</span> <span class="n">isotonic_regression</span>

<span class="n">isotonic_regression_cal</span> <span class="o">=</span> <span class="n">isotonic_regression</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">use_logits</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">isotonic_regression_cal</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cal_loader</span><span class="p">)</span>

<span class="n">cal_probs_isotonic</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">labels_isotonic</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">x_to_device</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x_to_device</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">isotonic_regression_cal</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">cal_probs_isotonic</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
        <span class="n">labels_isotonic</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>

<span class="n">cal_probs_isotonic</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">cal_probs_isotonic</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">all_labels_isotonic</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">labels_isotonic</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">ece_calibrated_isotonic</span> <span class="o">=</span> <span class="n">expected_calibration_error</span><span class="p">(</span><span class="n">cal_probs_isotonic</span><span class="p">,</span> <span class="n">all_labels_isotonic</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected Calibration Error after Isotonic Regression: </span><span class="si">{</span><span class="n">ece_calibrated_isotonic</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">brier_calibrated_isotonic</span> <span class="o">=</span> <span class="n">brier_score</span><span class="p">(</span><span class="n">cal_probs_isotonic</span><span class="p">,</span> <span class="n">all_labels_isotonic</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Brier Score after Isotonic Regression: </span><span class="si">{</span><span class="n">brier_calibrated_isotonic</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">diagram_isotonic</span> <span class="o">=</span> <span class="n">compute_reliability_diagram</span><span class="p">(</span><span class="n">cal_probs_isotonic</span><span class="p">,</span> <span class="n">all_labels_isotonic</span><span class="p">)</span>
<span class="n">plot_reliability_diagram</span><span class="p">(</span><span class="n">diagram_isotonic</span><span class="p">,</span> <span class="s2">&quot;Isotonic Regression&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Expected Calibration Error after Isotonic Regression: 0.02634600209891798
Brier Score after Isotonic Regression: 0.2880699038505554
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(&lt;Figure size 640x480 with 1 Axes&gt;,
 &lt;Axes: title={&#39;center&#39;: &#39;Isotonic Regression&#39;}, xlabel=&#39;Confidence&#39;, ylabel=&#39;Accuracy&#39;&gt;)
</pre></div>
</div>
<img alt="../_images/8b2d7c770a35894e85df1b01ec7d6d1b065cd9b0854aa77b1c818a2c8ab44aca.png" src="../_images/8b2d7c770a35894e85df1b01ec7d6d1b065cd9b0854aa77b1c818a2c8ab44aca.png" />
</div>
</div>
<p>As we can see, the isotonic regression calibrated the models outputs and the brier score should have decreased. The ECE might not necessarily decrease since isotonic regression can over fit and thus slightly increase the ECE.</p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2025, probly team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=4621528c"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=5fa4622c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=ccdb6887"></script>
    </body>
</html>